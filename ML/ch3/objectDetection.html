<!DOCTYPE html>
<html lang="en">

<head>
    <title>Object Detection</title>
    <link rel="stylesheet" href="../../libraries/tachyons/tachyons.min.css">
    <script src="../../libraries/ml5.js"></script>
    <script src="../../libraries/p5.js"></script>
</head>

<body class="Roboto pa1 bg-near-white">
    <a href="../mlIndex.html" class="f4 no-underline blue bg-animate hover-bg-green hover-white inline-flex items-center pa3 ba border-box mr4">
        <span class="pl1">ML Home</span>
      </a>
    <a href="../../index.html" class="f4 no-underline black bg-animate hover-bg-orange hover-white inline-flex items-right pa3 ba border-box mr4">
      <span class="pr1">Home</span>
    </a>
    <section class="cf w-100 pv2 flex flex-wrap">
        <div class="fl w-100 f4 tl">
            <h1>Detecting Objects in the Scene</h1>
            <p class="f4 lh-copy">
                Live classification must have shown some limitation of the Mobilenet model, and 
                the method the ML classification works. We will improve on that by adding object 
                detection using ml5 object detector method that uses the <a href="https://cocodataset.org/#home">COCO</a>
                and <a href="https://pjreddie.com/darknet/yolo/">YOLO models</a>
            </p>
            <p class="f4 lh-copy bg-red white w-50" id="resOut"></p>
            <p class="f4 lh-copy">The learning was on the usage of P5's function to bring the bounding rectangles 
                around the objects. The model predicts the objects, along with their location and the approximate 
                bounding rectangles around them. It is provided as JSON file which can then be referred for creating 
                the rectangles, the labels etc
            </p>
        </div>
    </section>
    <script src="main.js"></script>
</body>
</html>